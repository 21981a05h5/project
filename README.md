# project
This project allows users to control a computer using hand gestures and voice commands, without using a physical mouse or keyboard. It uses Python, Machine Learning, and Deep Learning models like Xception, DenseNet, and AlexNet for gesture recognition.

Features:
Control mouse movement and clicks using hand gestures
Open applications and perform tasks using voice commands
Uses computer vision and speech recognition for interaction

Tech Used
Languages: Python

Libraries: OpenCV, PyAutoGUI, SpeechRecognition, TensorFlow/Keras

Models: Xception, DenseNet, AlexNet
